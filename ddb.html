<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <meta name="viewport" content="width=1024, user-scalable=no">

  <title>Distributed Databases</title>

  <link rel="stylesheet" media="screen" href="core/deck.core.css">
  <link rel="stylesheet" media="screen" href="extensions/goto/deck.goto.css">
  <link rel="stylesheet" media="screen" href="extensions/menu/deck.menu.css">
  <link rel="stylesheet" media="screen" href="extensions/navigation/deck.navigation.css">
  <link rel="stylesheet" media="screen" href="extensions/status/deck.status.css">
  <link rel="stylesheet" media="screen" href="extensions/scale/deck.scale.css">
  <link rel="stylesheet" media="screen" href="themes/style/black.css">
  <link rel="stylesheet" media="screen" href="themes/transition/horizontal-slide.css">
  <link rel="stylesheet" media="print" href="core/print.css">
  <script src="modernizr.custom.js"></script>
</head>
<body>
  <div class="deck-container">

    <section class="slide">
      <h1>Distributed Databases</h1>
    </section>

    <section class="slide">
      <h2>Why Go Distributed ?</h2>
      <ul>
        <li>Scale out</li>
        <li>Uptime</li>
      </ul>
      <h3>Our problems</h3>
      <ul>
        <li>servers die</li>
        <li>network is unreliable
        <ul>
         <li>Packet drop</li>
         <li>High latency</li>
         <li>Complete failure</li>
        </ul>
       </li>
      </ul>
      <img src="img/system-of-3.png" />
      <h3>=> Dreaded "split-brain" scenario in which a system splits and diverges</h3>
    </section>

    <section class="slide">
      <h2>Some Theory</h2>
      <ul>
        <li>ACID</li>
        <li>CAP</li>
        <li>Consensus Protocol</li>
        <li>Dynamo</li>
        <li>Bigtable</li>
      </ul>
    </section>

    <section class="slide">
      <h2>Traditional RDBMS: ACID</h2>
          <ul>
            <li>Atomicity: "All of nothing", if part fails, the entire transaction fails.</li>
            <li>Consistency: Follow databases rules (key, uniqueness).</li>
            <li>Isolation: Transactions will wait if at the same time and touching the same data.</li>
            <li>Durability: Once a transaction is commited, it stays so.</li>
          </ul>
          <ul>
            <li>In a one-node DB, this is easier, as the state is centralized.</li>
            <li><h4>=&gt; In a distributed environment, this requires high coordination (locks) to ensure linearizability of state changes</h4></li>
            <li>=&gt; Same issue at a much smaller scale in multi CPU machines: access to memory must be synchronized</li>
          </ul>
    </section>

    <section class="slide">
      <img src="img/linearizability.png" />
    </section>

    <section class="slide">
      <h2>CAP Principle (Eric Brewer in 2000)</h2>
          <img src="img/cap.svg" style="float:right;width:40%;background-color:white;" />
          <ul style="float:left;width:50%;">
            <li><b>Consistency</b>: All nodes always give the same answer. Not the same C in ACID.</li>
            <li><b>Availability</b>: Nodes always answer queries and accept updates.</li>
            <li><b>Parition-tolerance</b>: System continues working even if one or more nodes vanish.</li>
            <li><h4>=> P is not really avoidable, and you can only have two of these</h4></li>
            <li><h4>=> All about tradeoff between C and A through more or less asynchrone replication</h4></li>
            <li><h4>=> Also latency tradoff</h4></li>
          </ul>
    </section>

    <section class="slide">
      <h2>Consistency ?</h2>
      <img src="img/consistency-family-tree.jpg" style="float:right;width:40%;" />
      <ul style="float:left;width:50%;">
        <li>Linearizability</li>
        <li>Sequential consistency</li>
        <li>Causal consistency</li>
        <li>Serializable consistency</li>
        <li>...</li>
      </ul>
      <h2>CRDTs ?</h2>
      <ul>
        <li>CRDTs: Convergent/Commutative Replicated Data Types</li>
        <li>=> Datatypes designed so that the order of operations does not matter</li>
        <li>e.g. counters: increment(account, -100)</li>
      </ul>
      <p>Read more at https://aphyr.com/posts/313-strong-consistency-models</p>
    </section>

    <section class="slide">
      <h2>CAP Principle / Eventual Consistency</h2>
      <h3>NRW notation</h3>
      <ul>
        <li>N = the number of nodes that keep copies of a record distributed to.</li>
        <li>W = the number of nodes that must successfully acknowledge a write to be successfully committed.</li>
        <li>R = the number of nodes that must send back the same value of a unit of data for it to be accepted as read by the system.</li>
      </ul>
      <ul>
        <li>W &gt; N - high write availability</li>
        <li>R &gt; N - high read availability</li>
        <li>W+R &lt; N - is a strong consistency, read/write are fully overlapped</li>
        <li>W+R &lt;= N - is an eventual consistency, meaning that there is no overlap in the read and write set;</li>
      </ul>
    </section>

    <section class="slide">
      <h2>Consensus Protocol</h2>
      <h3>Paxos / Raft</h3>
      <ul>
        <li>Paxos (kinda) in Cassandra</li>
        <li>Only called for some queries with strong consistency requirements (IF NOT EXISTS)</li>
        <li>TODO: example</li>
        <li>Lots of new DBs uses the (simpler) Raft protocol</li>
      </ul>
    </section>

    <section class="slide">
      <h2>Dynamo</h2>
      <h3>Complementary approach to Paxos/Raft</h3>
      <table width="100%">
        <tr style="border:1px solid gray;">
          <th>Problem</th><th>Answer</th>
        </tr>
        <tr style="border:1px solid gray;">
          <td>Partitioning/Sharding</td><td>Consistent Hashing</td>
        </tr>
        <tr style="border:1px solid gray;">
          <td>Highly available writes</td><td>Vector Clock or last write wins policy</td>
        </tr>
        <tr style="border:1px solid gray;">
          <td>Temporary failures</td><td>Sloppy Quorum and Hinted Handoff</td>
        </tr>
        <tr style="border:1px solid gray;">
          <td>Recovery from failures</td><td>Anti-entropy using Merkle tree</td>
        </tr>
        <tr style="border:1px solid gray;">
          <td>Cluster membership, failure detection</td><td>Gossip Protocol</td>
        </tr>
      </table>
      <br>
      <ul>
        <li>Cassandra and Riak use all of these techniques (only last write wins for Cassandra).</li>
        <li>Redis Cluster only uses Consistent Hashing.</li>
      </ul>
    </section>

    <section class="slide">
      <h2>Dynamo - Consistent Hashing</h2>
      <table>
        <tr class="slide"><td><img src="img/ring-1.png" /></td><td><img src="img/ring-2.png" /></td></tr>
        <tr class="slide"><td><img src="img/ring-3.png" /></td><td><img src="img/ring-4.png" /></td></tr>
      </table>
    </section>

    <section class="slide">
      <h2>Dynamo - Merkle tree</h2>
      <ul>
        <li>hash tree</li>
        <li>used to detect changes in huge datasets (BitTorrent, Git)</li>
        <li>still quite costly to build:
        <ul>
          <li>Cassandra build and check them when running "nodetool repair"</li>
          <li>Riak does so automatically in background, and caches them</li>
        </li>
      </ul>
    </section>

    <section class="slide">
      <h2>Dynamo - Gossip Protocol</h2>
      <ul>
        <li>Decentralized way to manage cluster state</li>
        <li>Fixed network usage</li>
        <li>Used in Cassandra and Riak
        <ul>
          <li>TODO: add image</li>
        </li>
      </ul>
    </section>

    <section class="slide">
      <h2>Bigtable</h2>
      <h3>log-structured and ordered storage</h3>
<ul>
<li>Implementations<ul>
  <li>Apache Accumulo (built on top of Hadoop, ZooKeeper, and Thrift, Java)</li>
  <li>Apache Cassandra</li>
  <li>Apache HBase (BigTable-like support on the Hadoop Core, Java)</li>
  <li>Hypertable (designed to manage the storage and processing of information on a large cluster of commodity servers, C++)</li>
  <li>LevelDB (basic key/value format like sqlite)</li>
  </ul>
</li>
<li>Data model<ul>
  <li>The primary key uniquely identifies a row</li>
  <li>Partition key/Clustering columns/Values</li>
  <li>The partition key determines on which node the partition resides</li>
  <li>Data is ordered in cluster column order within the partition</li>
<li>TODO: add image</li>
  </ul>
</li>
</ul>
    </section>

    <section class="slide">
      <h2>Withings Use Cases</h2>
TODO: add volumetry
      <ul>
        <li class="slide">
        <h3>Vasistas, measure env., timeline: Cassandra (was in PostgreSQL)</h3>
        <ul>
          <li>support for range queries (e.g. select * from vasistas where ts>4 and ts<10)</li>
          <li>“linearly” scalable</li>
          <li>schema structured data (with validations)</li>
          <li>available (ok to shutdown one node)</li>
          <li>good support for timeseries</li>
          <li>good durability</li>
          <li>(nearly) append only</li>
          <li>(idealy) support for TTLs</li>
          <li>(idealy) have a nice query api</li>
        </ul>
      </li>
      
      <li class="slide">
        <h3>Profile Picture: Riak (was GlusterFS)</h3>
        <ul>
          <li>binary blobs</li>
          <li>key/value</li>
          <li>available (ok to shutdown one node)</li>
          <li>good durability</li>
        </ul>
      </li>

      <li class="slide">
        <h3>Redis Cluster</h3>
        <ul>
          <li>highly available (ok to shutdown one node)</li>
          <li>strongly consistent</li>
          <li>ttl per key</li>
          <li>light</li>
          <li>no need for (high) durability</li>
          <li>fast (very high throughput)</li>
        </ul>
      </li>
      </ul>
    </section>

    <section class="slide">
      <h2>Cassandra</h2>
      <ul>
        <li>Used in production since december 2014 for:
          <ul>
            <li>measures (temp, co2, ...) - was in PostgreSQL</li>
            <li>timeline (users, device, CVR, timelapse) - was in Redis, and new</li>
            <li>campaign (yearreview) - new</li>
          </ul>
        </li>
        <li>More recently, and partially, for:
          <ul>
            <li>vasistas - was in PostgreSQL</li>
          </ul>
        </li>
      <ul>
    </section>

    <section class="slide">
      <h2>Cassandra Write Path</h2>
      <ul>
        <li>Memtable + Commitlog</li>
        <li>SSTable flush</li>
        <li>Compactions
          <ul>
            <li>STCS: SizeTieredCompactionStrategy</li>
            <li>DTCS: DateTieredCompactionStrategy</li>
            <li>LCS: LeveledCompactionStrategy</li>
          </ul>
        </li>
        <li>Log-like structures are easier to work with: no tombstone</li>
      </ul>
      <img src="img/cas-write-path.png" style="background-color:white;" />
    </section>

    <section class="slide">
      <h2>Cassandra Data Model</h2>
      <h3>CREATE KEYSPACE</h3>
<pre>
CREATE KEYSPACE measure
  WITH replication = {
	'class': 'SimpleStrategy',
	'replication_factor': '2'
  } AND durable_writes = true;</pre>
      <ul>
        <li>SimpleStrategy: No datacenter replication</li>
        <li>replication_factor: How many times data is replicated</li>
        <li>durable_writes: Use commitlog</li>
      </ul>
    </section>

    <section class="slide">
      <h2>Cassandra Data Model Fail</h2>
      <h4>Data model for measures was</h4>
      <pre style="font-size:60%;">
CREATE TABLE measure.measure_12 (
    deviceid int,
    ts bigint,
    exp int,
    value int,
    PRIMARY KEY (deviceid, ts)
) WITH CLUSTERING ORDER BY (ts ASC)
    AND compaction = {'class': 'SizeTieredCompactionStrategy'}
    AND compression = {'sstable_compression': 'LZ4Compressor'};</pre>
      <ul>
        <li>Migration to DTCS (on the fly, but not perfect, see #8340)</li>
        <li>Change of compression level (on the fly)</li>
        <li>And finally, slight rework of the data model:</li>
      </ul>
      <pre style="font-size:60%;">
CREATE TABLE measure.measure_12_ng (
    deviceid int,
    ts bigint,
    vs map&lt;int, int&gt;,
    PRIMARY KEY (deviceid, ts)
) WITH CLUSTERING ORDER BY (ts ASC)
    AND compaction = {'max_sstable_age_days': '15', 'class': 'DateTieredCompactionStrategy'}
    AND compression = {'sstable_compression': 'DeflateCompressor'};</pre>
      <h4>=> Inspired by similar issue on vasistas</h4>
    </section>

    <section class="slide">
      <h2>Cassandra Data Model - Queries</h2>
      <h3>SELECT * FROM measure_12 WHERE ts > 1432915925;</h3>
      <ul>
		<li class="slide">
		<h3 style="color:red;">Nope: "Cannot execute this query as it might involve data filtering and thus may have unpredictable performance"</h3>
        <h3>SELECT * FROM measure_12 WHERE deviceid = 54545 AND value < 45;</h3>
        </li>
        <li class="slide">
        <h3 style="color:red;">Nope: "No secondary indexes on the restricted columns support the provided operators"</h3>
        <h3>SELECT * FROM measure_12 WHERE deviceid = 54545 AND ts > 1432915925;</h3>
        </li>
        <li class="slide">
		<pre>
 deviceid | ts         | exponent | value
----------+------------+----------+-------
    54545 | 1432915926 | -1       | 154
        </pre>
         <h3>Spark should help for data analysis but require lots of servers and RAM</h3>
        </li>
      </ul>
    </section>

    <section class="slide">
      <h2>Cassandra after 6 months</h2>
      <ul>
        <li>Good points
          <ul>
            <li>Shutdown of one node without downtime</li>
            <li>TTLs + DTCS great until now</li>
            <li>High write throughput</li>
            <li>Mistakes (data model, compactions) occured but solutions were found</li>
          </ul>
        </li>
        <li>Caveats
          <ul>
            <li>Java is a pita (when you don’t have a lot of xp): oom, gc</li>
            <li>Compactions are tricky to get right</li>
            <li>Storage overhead (globally, and especially per cell)</li>
            <li>No out of the box easily parsable (JSON) metrics without java</li>
          </ul>
        </li>
      </ul>
    </section>

    <section class="slide">
      <h2>Riak</h2>
      <ul>
        <li>Context
          <ul>
            <li>Used in HQ for more than 1 year for traces (High volumetry)</li>
            <li>Now used in production for P4 for just 1 month</li>
          </ul>
        </li>
        <li>Good points
          <ul>
            <li>Very stable and fast for traces</li>
            <li>Architecture seems well thought, defined</li>
          </ul>
        </li>
        <li>Operations
          <ul>
            <li>Erlang (but much better than ejabberd)</li>
            <li>Lots of metrics out of the box</li>
            <li>Not as straightforward as a file system operationally and in case of failure</li>
          </ul>
        </li>
      <ul>
    </section>

    <section class="slide">
      <h2>Redis Cluster</h2>
      <img src="img/redis-cluster.png" />
      <ul>
        <li>Relatively new to the stack</li>
        <li>Characteristics
          <ul>
            <li>Data access through text protocol</li>
            <li>In-memory (standard redis instances)</li>
            <li>Same ‘ring’ approach than riak and cassandra but sharding with explicit master/slave:</li>
            <li>Standard redis replication and persistence</li>
            <li>Not for high volumetry</li>
          </ul>
        </li>
        <li>Operations
          <ul>
            <li>All of redis metrics available (normal instances)</li>
            <li>Reliable (at least for base redis tech, redis-cluster 3.0.0 just out)</li>
            <li>C powa !</li>
          </ul>
        </li>
      <ul>
    </section>

    <section class="slide">
      <h2>Others</h2>
      <ul>
        <li>Elasticsearch: Used in next gen traces ws.</li>
        <li>MySQL Cluster: Seems mature and robust and fast: to investigate ?</li>
      </ul>
      <h2>Future</h2>
      <ul>
        <li>Google Spanner: No real open source implementations (CockroachDB). Seems complex.</li>
        <li>Cassandra 2.2/3.0: Aggregates ?</li>
      </ul>
      <h2>Refs</h2>
      <ul style="font-size:70%;">
        <li>Theory and practical DB analysis: https://aphyr.com/</li>
        <li>List of NoSQL DBs: http://nosql-database.org/</li>
        <li>Sloppy Quorums/Riak: http://lists.basho.com/pipermail/riak-users_lists.basho.com/2012-January/007157.html</li>
        <li>Sloppy Quorums: http://jimdowney.net/2012/03/05/be-careful-with-sloppy-quorums/</li>
        <li>Merkle/Hash tree: http://en.wikipedia.org/wiki/Merkle_tree</li>
        <li>CAP: http://en.wikipedia.org/wiki/CAP_theorem</li>
        <li>CAP/PAC: https://redeyemon.wordpress.com/2010/10/08/cap-theory-should-have-been-pac-theory/</li>
        <li>CAP: http://fr.slideshare.net/YoavFrancis/cap-theorem-theory-implications-and-practices</li>
        <li>CAP/ACID: http://berb.github.io/diploma-thesis/community/061_challenge.html</li>
        <li>CRDTs: http://hal.upmc.fr/file/index/docid/555588/filename/techreport.pdf</li>
        <li>Spanner paper: https://www.usenix.org/system/files/conference/osdi12/osdi12-final-16.pdf</li>
      </ul>
    </section>
    <!-- End slides. -->

    <!-- deck.navigation snippet -->
    <div aria-role="navigation">
      <a href="#" class="deck-prev-link" title="Previous">&#8592;</a>
      <a href="#" class="deck-next-link" title="Next">&#8594;</a>
    </div>

    <!-- deck.status snippet -->
    <p class="deck-status" aria-role="status">
      <span class="deck-status-current"></span>
      /
      <span class="deck-status-total"></span>
    </p>

    <!-- deck.goto snippet -->
    <form action="." method="get" class="goto-form">
      <label for="goto-slide">Go to slide:</label>
      <input type="text" name="slidenum" id="goto-slide" list="goto-datalist">
      <datalist id="goto-datalist"></datalist>
      <input type="submit" value="Go">
    </form>

    <!-- End extension snippets. -->
  </div>

<!-- Required JS files. -->
<script src="jquery.min.js"></script>
<script src="core/deck.core.js"></script>

<!-- Extension JS files. Add or remove as needed. -->
<script src="extensions/menu/deck.menu.js"></script>
<script src="extensions/goto/deck.goto.js"></script>
<script src="extensions/status/deck.status.js"></script>
<script src="extensions/navigation/deck.navigation.js"></script>
<script src="extensions/scale/deck.scale.js"></script>

<!-- Initialize the deck. You can put this in an external file if desired. -->
<script>
  $(function() {
    $.deck('.slide');
  });
</script>
</body>
</html>
